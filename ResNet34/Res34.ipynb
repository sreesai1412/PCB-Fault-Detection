{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Res34.ipynb","provenance":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Vkl37VKlFpBm","colab_type":"code","outputId":"c69a3b10-c209-41f3-d2f3-c7edbd3f532e","executionInfo":{"status":"ok","timestamp":1579938878796,"user_tz":-330,"elapsed":3024,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import os,cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from keras import backend as K\n","from keras.utils import np_utils\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation, Flatten\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D\n","from keras.optimizers import SGD,RMSprop,adam\n","import tensorflow as tf"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Klm-jJnMDI7R","colab_type":"code","outputId":"deee48d6-618e-452d-fb95-8e1f5fa19425","executionInfo":{"status":"ok","timestamp":1579938878797,"user_tz":-330,"elapsed":2998,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","if tf.test.gpu_device_name():\n","    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n","else:\n","    print(\"Please install GPU version of TF\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Default GPU Device: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fjvgSViEDbNi","colab_type":"code","outputId":"a4590cfc-00da-40a8-af67-8df643847ad7","executionInfo":{"status":"ok","timestamp":1579938878798,"user_tz":-330,"elapsed":2977,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["import keras\n","keras.backend.clear_session()\n","import numpy as np\n","import tensorflow as tf\n","import random as rn\n","\n","# The below is necessary for starting Numpy generated random numbers\n","# in a well-defined initial state.\n","\n","np.random.seed(42)\n","\n","# The below is necessary for starting core Python generated random numbers\n","# in a well-defined state.\n","\n","rn.seed(12345)\n","\n","# Force TensorFlow to use single thread.\n","# Multiple threads are a potential source of non-reproducible results.\n","# For further details, see: https://stackoverflow.com/questions/42022950/\n","\n","session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n","                              inter_op_parallelism_threads=1)\n","\n","from keras import backend as K\n","\n","# The below tf.set_random_seed() will make random number generation\n","# in the TensorFlow backend have a well-defined initial state.\n","# For further details, see:\n","# https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n","\n","tf.set_random_seed(1234)\n","\n","sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n","K.set_session(sess)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PQZ7yPB0GLFi","colab_type":"code","outputId":"0c5772d7-0d4c-4928-bf40-272d13fb6c3a","executionInfo":{"status":"ok","timestamp":1579938878799,"user_tz":-330,"elapsed":2949,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YcjPTdeaFpB3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":358},"outputId":"e05d808c-7693-47cc-bbc3-2baa3e5d706f","executionInfo":{"status":"error","timestamp":1579940179080,"user_tz":-330,"elapsed":198030,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}}},"source":["os.chdir('/content/drive/My Drive/PCB/Train_Data')\n","train_x = np.load('train_X.npy')\n","train_x = train_x[:,100:200,100:200,:]\n","train_y = np.load('train_y.npy')"],"execution_count":9,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-8c2807010c1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/PCB/Train_Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_X.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_y.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 453\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"iA4YOk_ct8rB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"bfe85b68-fd8e-4b94-bb1b-2f3fe9a9efd8","executionInfo":{"status":"ok","timestamp":1579939462460,"user_tz":-330,"elapsed":1580,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}}},"source":["train_y = tf.convert_to_tensor(train_y, np.float32)\n","sess = tf.InteractiveSession()\n","print(train_y.eval())\n","sess.close()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[0. 0. 0. ... 1. 1. 1.]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"MP7n3FcZFpB9","colab_type":"code","outputId":"4ac731e0-849d-4d65-fe4c-71049f28f142","executionInfo":{"status":"ok","timestamp":1579348170136,"user_tz":-330,"elapsed":4025,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["num_classes = 2\n","print(np.unique(train_y,return_counts=True))\n","train_y= np_utils.to_categorical(train_y, num_classes)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(array([0., 1.]), array([15000, 15000]))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Mwoa6PBFpCF","colab_type":"code","outputId":"d883d07e-ee36-42ca-ba4b-68a4f327a80d","executionInfo":{"status":"ok","timestamp":1579348170139,"user_tz":-330,"elapsed":2559,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["print(len(train_x))\n","print(len(train_y))\n","print(train_x.shape)\n","print(train_y.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["30000\n","30000\n","(30000, 100, 100, 3)\n","(30000, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9r91tpe5FpCM","colab_type":"code","outputId":"0cfcc1ff-e06c-4471-b3c7-2427f36865ff","executionInfo":{"status":"ok","timestamp":1579348182655,"user_tz":-330,"elapsed":13461,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["mean = np.mean(train_x)\n","std = np.std(train_x)\n","print (mean, std)\n","\n","train_x = train_x - mean\n","train_x = train_x / std\n","print(train_x.shape)\n","print(train_y.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["62.34926454777778 58.207460392701165\n","(30000, 100, 100, 3)\n","(30000, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GGDKVQlqFpCT","colab_type":"code","outputId":"302e9383-fb71-49af-83b6-ceecb1335465","executionInfo":{"status":"ok","timestamp":1579348186621,"user_tz":-330,"elapsed":3113,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["X_train, X_valid, y_train, y_valid = train_test_split(train_x, train_y, test_size=0.2, random_state=2)\n","\n","print(len(X_train))\n","print(len(y_train))\n","\n","print(\"\")\n","\n","print(len(X_valid))\n","print(len(y_valid))\n","\n","print(\"\")\n","\n","print(X_train.shape)\n","print(y_train.shape)\n","\n","print(\"\")\n","\n","print(X_valid.shape)\n","print(y_valid.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["24000\n","24000\n","\n","6000\n","6000\n","\n","(24000, 100, 100, 3)\n","(24000, 2)\n","\n","(6000, 100, 100, 3)\n","(6000, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9_-VfALgFpCZ","colab_type":"code","outputId":"6e0290e6-549a-4e29-ca01-4b569da60ead","executionInfo":{"status":"ok","timestamp":1579348189408,"user_tz":-330,"elapsed":4611,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["X_train = X_train.astype('float32')\n","y_train = y_train.astype('float32')\n","#y_train = np.reshape(y_train,(-1,1))\n","\n","X_valid = X_valid.astype('float32')\n","y_valid = y_valid.astype('float32')\n","#y_valid = np.reshape(y_valid,(-1,1))\n","\n","\n","print(X_train.shape)\n","print(y_train.shape)\n","print(\"\")\n","print(X_valid.shape)\n","print(y_valid.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(24000, 100, 100, 3)\n","(24000, 2)\n","\n","(6000, 100, 100, 3)\n","(6000, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_pfeBVduFpCd","colab_type":"code","outputId":"f97f5756-d8e7-47f0-80ef-52d183a18f11","executionInfo":{"status":"ok","timestamp":1579348199078,"user_tz":-330,"elapsed":12929,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras import layers\n","from keras.models import Model\n","\n","def _after_conv(in_tensor):\n","    norm = layers.BatchNormalization()(in_tensor)\n","    return layers.Activation('relu')(norm)\n","\n","def conv1(in_tensor, filters):\n","    conv = layers.Conv2D(filters, kernel_size=1, strides=1)(in_tensor)\n","    return _after_conv(conv)\n","\n","def conv1_downsample(in_tensor, filters):\n","    conv = layers.Conv2D(filters, kernel_size=1, strides=2)(in_tensor)\n","    return _after_conv(conv)\n","\n","def conv3(in_tensor, filters):\n","    conv = layers.Conv2D(filters, kernel_size=3, strides=1, padding='same')(in_tensor)\n","    return _after_conv(conv)\n","\n","def conv3_downsample(in_tensor, filters):\n","    conv = layers.Conv2D(filters, kernel_size=3, strides=2, padding='same')(in_tensor)\n","    return _after_conv(conv)\n","\n","def resnet_block_wo_bottlneck(in_tensor, filters, downsample=False):\n","    if downsample:\n","        conv1_rb = conv3_downsample(in_tensor, filters)\n","    else:\n","        conv1_rb = conv3(in_tensor, filters)\n","    conv2_rb = conv3(conv1_rb, filters)\n","\n","    if downsample:\n","        in_tensor = conv1_downsample(in_tensor, filters)\n","    result = layers.Add()([conv2_rb, in_tensor])\n","\n","    return layers.Activation('relu')(result)\n","\n","def resnet_block_w_bottlneck(in_tensor,\n","                             filters,\n","                             downsample=False,\n","                             change_channels=False):\n","    if downsample:\n","        conv1_rb = conv1_downsample(in_tensor, int(filters/4))\n","    else:\n","        conv1_rb = conv1(in_tensor, int(filters/4))\n","    conv2_rb = conv3(conv1_rb, int(filters/4))\n","    conv3_rb = conv1(conv2_rb, filters)\n","\n","    if downsample:\n","        in_tensor = conv1_downsample(in_tensor, filters)\n","    elif change_channels:\n","        in_tensor = conv1(in_tensor, filters)\n","    result = layers.Add()([conv3_rb, in_tensor])\n","\n","    return result\n","\n","def _pre_res_blocks(in_tensor):\n","    conv = layers.Conv2D(64, 7, strides=2, padding='same')(in_tensor)\n","    conv = _after_conv(conv)\n","    pool = layers.MaxPool2D(3, 2, padding='same')(conv)\n","    return pool\n","\n","def _post_res_blocks(in_tensor, n_classes):\n","    pool = layers.GlobalAvgPool2D()(in_tensor)\n","    preds = layers.Dense(n_classes, activation='softmax')(pool)\n","    return preds\n","\n","def convx_wo_bottleneck(in_tensor, filters, n_times, downsample_1=False):\n","    res = in_tensor\n","    for i in range(n_times):\n","        if i == 0:\n","            res = resnet_block_wo_bottlneck(res, filters, downsample_1)\n","        else:\n","            res = resnet_block_wo_bottlneck(res, filters)\n","    return res\n","\n","def convx_w_bottleneck(in_tensor, filters, n_times, downsample_1=False):\n","    res = in_tensor\n","    for i in range(n_times):\n","        if i == 0:\n","            res = resnet_block_w_bottlneck(res, filters, downsample_1, not downsample_1)\n","        else:\n","            res = resnet_block_w_bottlneck(res, filters)\n","    return res\n","\n","def _resnet(in_shape=(224,224,3),\n","            n_classes=1000,\n","            convx=[64, 128, 256, 512],\n","            n_convx=[2, 2, 2, 2],\n","            convx_fn=convx_wo_bottleneck):\n","    in_layer = layers.Input(in_shape)\n","\n","    downsampled = _pre_res_blocks(in_layer)\n","\n","    conv2x = convx_fn(downsampled, convx[0], n_convx[0])\n","    conv3x = convx_fn(conv2x, convx[1], n_convx[1], True)\n","    conv4x = convx_fn(conv3x, convx[2], n_convx[2], True)\n","    conv5x = convx_fn(conv4x, convx[3], n_convx[3], True)\n","\n","    preds = _post_res_blocks(conv5x, n_classes)\n","\n","    model = Model(in_layer, preds)\n","    return model\n","\n","def resnet18(in_shape=(100,100,3), n_classes=2):\n","    return _resnet(in_shape, n_classes)\n","\n","def resnet34(in_shape=(100,100,3), n_classes=2):\n","    return _resnet(in_shape,n_classes,n_convx=[3, 4, 6, 3])\n","\n","def resnet50(in_shape=(300,300,3), n_classes=2):\n","    return _resnet(in_shape,n_classes,[256, 512, 1024, 2048],[3, 4, 6, 3],convx_w_bottleneck)\n","\n","def resnet101(in_shape=(300,300,3), n_classes=2):\n","    return _resnet(in_shape,n_classes,[256, 512, 1024, 2048],[3, 4, 23, 3],convx_w_bottleneck)\n","\n","def resnet152(in_shape=(300,300,3), n_classes=2):\n","    return _resnet(in_shape,n_classes,[256, 512, 1024, 2048],[3, 8, 36, 3],convx_w_bottleneck)\n","\n","if __name__ == '__main__':\n","    model = resnet34()\n","    print(model.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 100, 100, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 50, 50, 64)   9472        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 50, 50, 64)   256         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 50, 50, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 64)   0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 25, 25, 64)   36928       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 25, 25, 64)   256         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 25, 25, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 25, 25, 64)   36928       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 25, 25, 64)   256         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 25, 25, 64)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 25, 25, 64)   0           activation_3[0][0]               \n","                                                                 max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 25, 25, 64)   0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 25, 25, 64)   36928       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 25, 25, 64)   256         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 25, 25, 64)   36928       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 25, 25, 64)   256         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 25, 25, 64)   0           activation_6[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 25, 25, 64)   0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 25, 25, 64)   36928       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 25, 25, 64)   256         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 25, 25, 64)   36928       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 25, 25, 64)   256         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 25, 25, 64)   0           activation_9[0][0]               \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 25, 25, 64)   0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 13, 13, 128)  73856       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 13, 13, 128)  512         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 13, 13, 128)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 13, 13, 128)  147584      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 13, 13, 128)  8320        activation_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 13, 13, 128)  512         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 13, 13, 128)  512         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 13, 13, 128)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 13, 13, 128)  0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 13, 13, 128)  0           activation_12[0][0]              \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 13, 13, 128)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 13, 13, 128)  147584      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 13, 13, 128)  512         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 13, 13, 128)  0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 13, 13, 128)  147584      activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 13, 13, 128)  512         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 13, 13, 128)  0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 13, 13, 128)  0           activation_16[0][0]              \n","                                                                 activation_14[0][0]              \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 13, 13, 128)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 13, 13, 128)  147584      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 13, 13, 128)  512         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 13, 13, 128)  0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 13, 13, 128)  147584      activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 13, 13, 128)  512         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 13, 13, 128)  0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 13, 13, 128)  0           activation_19[0][0]              \n","                                                                 activation_17[0][0]              \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 13, 13, 128)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 13, 13, 128)  147584      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 13, 13, 128)  512         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 13, 13, 128)  0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 13, 13, 128)  147584      activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 13, 13, 128)  512         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 13, 13, 128)  0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 13, 13, 128)  0           activation_22[0][0]              \n","                                                                 activation_20[0][0]              \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 13, 13, 128)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 7, 7, 256)    295168      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 7, 7, 256)    1024        conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 7, 7, 256)    0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 7, 7, 256)    590080      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 7, 7, 256)    33024       activation_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 7, 7, 256)    1024        conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 7, 7, 256)    1024        conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 7, 7, 256)    0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 7, 7, 256)    0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 7, 7, 256)    0           activation_25[0][0]              \n","                                                                 activation_26[0][0]              \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 7, 7, 256)    0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 7, 7, 256)    590080      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 7, 7, 256)    1024        conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 7, 7, 256)    0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 7, 7, 256)    590080      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 7, 7, 256)    1024        conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 7, 7, 256)    0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 7, 7, 256)    0           activation_29[0][0]              \n","                                                                 activation_27[0][0]              \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 7, 7, 256)    0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 7, 7, 256)    590080      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 7, 7, 256)    1024        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 7, 7, 256)    0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 7, 7, 256)    590080      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 7, 7, 256)    1024        conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 7, 7, 256)    0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 7, 7, 256)    0           activation_32[0][0]              \n","                                                                 activation_30[0][0]              \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 7, 7, 256)    0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 7, 7, 256)    590080      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 7, 7, 256)    1024        conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 7, 7, 256)    0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 7, 7, 256)    590080      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 7, 7, 256)    1024        conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 7, 7, 256)    0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 7, 7, 256)    0           activation_35[0][0]              \n","                                                                 activation_33[0][0]              \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 7, 7, 256)    0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 7, 7, 256)    590080      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 7, 7, 256)    1024        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 7, 7, 256)    0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 7, 7, 256)    590080      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 7, 7, 256)    1024        conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 7, 7, 256)    0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 7, 7, 256)    0           activation_38[0][0]              \n","                                                                 activation_36[0][0]              \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 7, 7, 256)    0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 7, 7, 256)    590080      activation_39[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 7, 7, 256)    1024        conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 7, 7, 256)    0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 7, 7, 256)    590080      activation_40[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 7, 7, 256)    1024        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 7, 7, 256)    0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 7, 7, 256)    0           activation_41[0][0]              \n","                                                                 activation_39[0][0]              \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 7, 7, 256)    0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 4, 4, 512)    1180160     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 4, 4, 512)    2048        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 4, 4, 512)    0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 4, 4, 512)    2359808     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 4, 4, 512)    131584      activation_42[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 4, 4, 512)    2048        conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 4, 4, 512)    2048        conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 4, 4, 512)    0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 4, 4, 512)    0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 4, 4, 512)    0           activation_44[0][0]              \n","                                                                 activation_45[0][0]              \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 4, 4, 512)    0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 4, 4, 512)    2359808     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 4, 4, 512)    2048        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 4, 4, 512)    0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 4, 4, 512)    2359808     activation_47[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 4, 4, 512)    2048        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 4, 4, 512)    0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 4, 4, 512)    0           activation_48[0][0]              \n","                                                                 activation_46[0][0]              \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 4, 4, 512)    0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 4, 4, 512)    2359808     activation_49[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 4, 4, 512)    2048        conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 4, 4, 512)    0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 4, 4, 512)    2359808     activation_50[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 4, 4, 512)    2048        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 4, 4, 512)    0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 4, 4, 512)    0           activation_51[0][0]              \n","                                                                 activation_49[0][0]              \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 4, 4, 512)    0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_1 (Glo (None, 512)          0           activation_52[0][0]              \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 2)            1026        global_average_pooling2d_1[0][0] \n","==================================================================================================\n","Total params: 21,311,234\n","Trainable params: 21,294,210\n","Non-trainable params: 17,024\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yfbVtx5YFpCi","colab_type":"code","colab":{}},"source":["# os.chdir('/content/drive/My Drive/PCB/Models/Res34/Results')\n","# from keras.callbacks import ModelCheckpoint,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler,EarlyStopping\n","# mc = ModelCheckpoint('PCB3_Res34_Aug_data_100*100.h5', monitor='val_loss', mode='min',save_best_only=True)\n","# es = EarlyStopping(monitor='val_loss', min_delta=0, patience=25, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n","# cv = CSVLogger('PCB3_Res34_Aug_data_100*100.csv',append=True)\n","# tensorboard_callback = TensorBoard(log_dir='logs', histogram_freq=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ftLuapKPFpCl","colab_type":"code","colab":{}},"source":["import keras\n","adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n","model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qd_Vh6PkFpCr","colab_type":"code","outputId":"9aa3becf-2f9b-4dcc-8b95-7d9331ca2c16","executionInfo":{"status":"ok","timestamp":1579353010993,"user_tz":-330,"elapsed":4693761,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["batch_size = 32\n","epochs = 100\n","history = model.fit(X_train,y_train,batch_size=batch_size,epochs=epochs,validation_data=(X_valid,y_valid),verbose = 1,shuffle=True)    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Train on 24000 samples, validate on 6000 samples\n","Epoch 1/100\n","24000/24000 [==============================] - 62s 3ms/step - loss: 0.4952 - acc: 0.8045 - val_loss: 1.3657 - val_acc: 0.6108\n","Epoch 2/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.2999 - acc: 0.8788 - val_loss: 3.3351 - val_acc: 0.5848\n","Epoch 3/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.2202 - acc: 0.9160 - val_loss: 0.2824 - val_acc: 0.8855\n","Epoch 4/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.1878 - acc: 0.9288 - val_loss: 0.2819 - val_acc: 0.8873\n","Epoch 5/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.1635 - acc: 0.9384 - val_loss: 0.1549 - val_acc: 0.9412\n","Epoch 6/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.1468 - acc: 0.9459 - val_loss: 0.3512 - val_acc: 0.8805\n","Epoch 7/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.1348 - acc: 0.9508 - val_loss: 0.1556 - val_acc: 0.9403\n","Epoch 8/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.1722 - acc: 0.9374 - val_loss: 0.1668 - val_acc: 0.9370\n","Epoch 9/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.1241 - acc: 0.9539 - val_loss: 0.2189 - val_acc: 0.9180\n","Epoch 10/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.1063 - acc: 0.9604 - val_loss: 0.1261 - val_acc: 0.9525\n","Epoch 11/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.1082 - acc: 0.9599 - val_loss: 0.1281 - val_acc: 0.9498\n","Epoch 12/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.1078 - acc: 0.9598 - val_loss: 0.1282 - val_acc: 0.9498\n","Epoch 13/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0880 - acc: 0.9665 - val_loss: 0.1179 - val_acc: 0.9557\n","Epoch 14/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0797 - acc: 0.9707 - val_loss: 0.1249 - val_acc: 0.9533\n","Epoch 15/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0737 - acc: 0.9729 - val_loss: 0.2134 - val_acc: 0.9237\n","Epoch 16/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0669 - acc: 0.9754 - val_loss: 0.1669 - val_acc: 0.9420\n","Epoch 17/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0677 - acc: 0.9748 - val_loss: 0.1486 - val_acc: 0.9505\n","Epoch 18/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0597 - acc: 0.9787 - val_loss: 0.1298 - val_acc: 0.9565\n","Epoch 19/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0566 - acc: 0.9793 - val_loss: 0.3273 - val_acc: 0.9380\n","Epoch 20/100\n","24000/24000 [==============================] - 46s 2ms/step - loss: 0.0520 - acc: 0.9821 - val_loss: 0.1401 - val_acc: 0.9512\n","Epoch 21/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0536 - acc: 0.9810 - val_loss: 0.1515 - val_acc: 0.9562\n","Epoch 22/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0478 - acc: 0.9826 - val_loss: 0.1510 - val_acc: 0.9555\n","Epoch 23/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0424 - acc: 0.9855 - val_loss: 0.1732 - val_acc: 0.9528\n","Epoch 24/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0398 - acc: 0.9864 - val_loss: 0.1705 - val_acc: 0.9515\n","Epoch 25/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0553 - acc: 0.9803 - val_loss: 0.1529 - val_acc: 0.9487\n","Epoch 26/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0397 - acc: 0.9852 - val_loss: 0.1463 - val_acc: 0.9550\n","Epoch 27/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0402 - acc: 0.9861 - val_loss: 0.1463 - val_acc: 0.9570\n","Epoch 28/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0306 - acc: 0.9889 - val_loss: 0.2046 - val_acc: 0.9487\n","Epoch 29/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0281 - acc: 0.9900 - val_loss: 0.1748 - val_acc: 0.9552\n","Epoch 30/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0293 - acc: 0.9890 - val_loss: 0.1779 - val_acc: 0.9548\n","Epoch 31/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0310 - acc: 0.9896 - val_loss: 0.2385 - val_acc: 0.9403\n","Epoch 32/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0280 - acc: 0.9898 - val_loss: 0.2102 - val_acc: 0.9455\n","Epoch 33/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0279 - acc: 0.9897 - val_loss: 0.1605 - val_acc: 0.9598\n","Epoch 34/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0266 - acc: 0.9903 - val_loss: 1.2504 - val_acc: 0.7722\n","Epoch 35/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0259 - acc: 0.9911 - val_loss: 0.1518 - val_acc: 0.9598\n","Epoch 36/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0238 - acc: 0.9918 - val_loss: 0.2381 - val_acc: 0.9382\n","Epoch 37/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0236 - acc: 0.9911 - val_loss: 0.1911 - val_acc: 0.9568\n","Epoch 38/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0220 - acc: 0.9919 - val_loss: 0.1961 - val_acc: 0.9558\n","Epoch 39/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0205 - acc: 0.9926 - val_loss: 0.1836 - val_acc: 0.9572\n","Epoch 40/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0232 - acc: 0.9925 - val_loss: 0.1988 - val_acc: 0.9538\n","Epoch 41/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0182 - acc: 0.9935 - val_loss: 0.4525 - val_acc: 0.9198\n","Epoch 42/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0195 - acc: 0.9932 - val_loss: 0.2102 - val_acc: 0.9517\n","Epoch 43/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0190 - acc: 0.9930 - val_loss: 0.1820 - val_acc: 0.9573\n","Epoch 44/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0216 - acc: 0.9928 - val_loss: 0.1957 - val_acc: 0.9553\n","Epoch 45/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0171 - acc: 0.9945 - val_loss: 0.2111 - val_acc: 0.9553\n","Epoch 46/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0194 - acc: 0.9933 - val_loss: 0.1920 - val_acc: 0.9543\n","Epoch 47/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0195 - acc: 0.9938 - val_loss: 0.2252 - val_acc: 0.9518\n","Epoch 48/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0261 - acc: 0.9919 - val_loss: 4.0476 - val_acc: 0.7153\n","Epoch 49/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.1714 - acc: 0.9630 - val_loss: 0.2753 - val_acc: 0.9402\n","Epoch 50/100\n","24000/24000 [==============================] - 46s 2ms/step - loss: 0.0303 - acc: 0.9892 - val_loss: 0.3842 - val_acc: 0.9445\n","Epoch 51/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0162 - acc: 0.9942 - val_loss: 0.3575 - val_acc: 0.9465\n","Epoch 52/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0167 - acc: 0.9945 - val_loss: 0.3269 - val_acc: 0.9478\n","Epoch 53/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0129 - acc: 0.9953 - val_loss: 0.4142 - val_acc: 0.9423\n","Epoch 54/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0114 - acc: 0.9962 - val_loss: 0.3889 - val_acc: 0.9467\n","Epoch 55/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0137 - acc: 0.9951 - val_loss: 0.2654 - val_acc: 0.9537\n","Epoch 56/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0118 - acc: 0.9959 - val_loss: 0.2577 - val_acc: 0.9527\n","Epoch 57/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0155 - acc: 0.9947 - val_loss: 0.2243 - val_acc: 0.9572\n","Epoch 58/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0148 - acc: 0.9946 - val_loss: 0.1894 - val_acc: 0.9563\n","Epoch 59/100\n","24000/24000 [==============================] - 46s 2ms/step - loss: 0.0112 - acc: 0.9957 - val_loss: 0.2586 - val_acc: 0.9543\n","Epoch 60/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0117 - acc: 0.9961 - val_loss: 0.2770 - val_acc: 0.9468\n","Epoch 61/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0120 - acc: 0.9955 - val_loss: 0.2085 - val_acc: 0.9585\n","Epoch 62/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0107 - acc: 0.9963 - val_loss: 0.2446 - val_acc: 0.9522\n","Epoch 63/100\n","24000/24000 [==============================] - 46s 2ms/step - loss: 0.0113 - acc: 0.9960 - val_loss: 0.1956 - val_acc: 0.9615\n","Epoch 64/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0088 - acc: 0.9971 - val_loss: 0.2095 - val_acc: 0.9608\n","Epoch 65/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.2424 - val_acc: 0.9523\n","Epoch 66/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0093 - acc: 0.9968 - val_loss: 0.2348 - val_acc: 0.9585\n","Epoch 67/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0118 - acc: 0.9961 - val_loss: 0.2007 - val_acc: 0.9578\n","Epoch 68/100\n","24000/24000 [==============================] - 46s 2ms/step - loss: 0.0082 - acc: 0.9970 - val_loss: 0.2800 - val_acc: 0.9528\n","Epoch 69/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0095 - acc: 0.9967 - val_loss: 0.2494 - val_acc: 0.9553\n","Epoch 70/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0092 - acc: 0.9966 - val_loss: 0.2438 - val_acc: 0.9595\n","Epoch 71/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0082 - acc: 0.9975 - val_loss: 0.2638 - val_acc: 0.9532\n","Epoch 72/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0096 - acc: 0.9968 - val_loss: 0.2020 - val_acc: 0.9573\n","Epoch 73/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0073 - acc: 0.9978 - val_loss: 0.2305 - val_acc: 0.9583\n","Epoch 74/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.2430 - val_acc: 0.9540\n","Epoch 75/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.2546 - val_acc: 0.9560\n","Epoch 76/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0082 - acc: 0.9975 - val_loss: 0.2449 - val_acc: 0.9580\n","Epoch 77/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0082 - acc: 0.9966 - val_loss: 0.2422 - val_acc: 0.9560\n","Epoch 78/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.2321 - val_acc: 0.9582\n","Epoch 79/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.5327 - val_acc: 0.9003\n","Epoch 80/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0088 - acc: 0.9970 - val_loss: 0.2720 - val_acc: 0.9535\n","Epoch 81/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0058 - acc: 0.9977 - val_loss: 0.2665 - val_acc: 0.9582\n","Epoch 82/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0079 - acc: 0.9972 - val_loss: 0.2592 - val_acc: 0.9557\n","Epoch 83/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0038 - acc: 0.9986 - val_loss: 0.2904 - val_acc: 0.9535\n","Epoch 84/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0081 - acc: 0.9973 - val_loss: 0.2526 - val_acc: 0.9575\n","Epoch 85/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0065 - acc: 0.9977 - val_loss: 0.3279 - val_acc: 0.9410\n","Epoch 86/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.2359 - val_acc: 0.9572\n","Epoch 87/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0069 - acc: 0.9980 - val_loss: 0.2620 - val_acc: 0.9552\n","Epoch 88/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0076 - acc: 0.9974 - val_loss: 0.2281 - val_acc: 0.9603\n","Epoch 89/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0058 - acc: 0.9979 - val_loss: 0.2452 - val_acc: 0.9580\n","Epoch 90/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0074 - acc: 0.9973 - val_loss: 0.2838 - val_acc: 0.9465\n","Epoch 91/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.2275 - val_acc: 0.9563\n","Epoch 92/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0075 - acc: 0.9974 - val_loss: 0.2359 - val_acc: 0.9562\n","Epoch 93/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0057 - acc: 0.9981 - val_loss: 0.2348 - val_acc: 0.9552\n","Epoch 94/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0042 - acc: 0.9981 - val_loss: 0.2826 - val_acc: 0.9497\n","Epoch 95/100\n","24000/24000 [==============================] - 46s 2ms/step - loss: 0.0073 - acc: 0.9974 - val_loss: 0.2642 - val_acc: 0.9537\n","Epoch 96/100\n","24000/24000 [==============================] - 46s 2ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.2548 - val_acc: 0.9573\n","Epoch 97/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.2799 - val_acc: 0.9572\n","Epoch 98/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.2925 - val_acc: 0.9515\n","Epoch 99/100\n","24000/24000 [==============================] - 46s 2ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.2927 - val_acc: 0.9553\n","Epoch 100/100\n","24000/24000 [==============================] - 47s 2ms/step - loss: 0.0076 - acc: 0.9978 - val_loss: 0.2049 - val_acc: 0.9600\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UjlspN_5FpCw","colab_type":"code","outputId":"f258d422-15bd-4929-82fc-0774cebd86d1","executionInfo":{"status":"ok","timestamp":1579353023319,"user_tz":-330,"elapsed":6383,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["os.chdir('/content/drive/My Drive/PCB/Test_Data')\n","\n","unseen_d = np.load('test_X.npy')\n","unseen_l = np.load('test_y.npy')\n","\n","from sklearn.model_selection import train_test_split\n","\n","x_train, x_valid, y_train, y_valid = train_test_split(unseen_d, unseen_l, test_size=0.2, shuffle= True)\n","\n","print(unseen_d.shape)\n","print(unseen_l.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2838, 300, 300, 3)\n","(2838,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"82l0zM5LJ7hv","colab_type":"code","outputId":"4edffaa7-abd3-4cca-fe2e-fd1648da8b44","executionInfo":{"status":"ok","timestamp":1579353028104,"user_tz":-330,"elapsed":2152,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["unseen_d=unseen_d[:,100:200,100:200,:];\n","print(unseen_d.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2838, 100, 100, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LJd_4FYqKAVp","colab_type":"code","outputId":"99f5de7c-15e7-4b7b-ae07-3ef9de4b492b","executionInfo":{"status":"ok","timestamp":1579353032727,"user_tz":-330,"elapsed":1827,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["unseen_d = unseen_d.reshape(unseen_d.shape[0],100,100,3).astype('float32')\n","mean=62.34\n","std=58.20\n"," \n","unseen_d = unseen_d - mean\n","unseen_d = unseen_d / std\n","print (unseen_d.shape)\n","unseen_d = unseen_d.astype('float32')\n","unseen_l = unseen_l.astype('float32')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2838, 100, 100, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-9-3r-MyKDrb","colab_type":"code","outputId":"b1e44929-0b55-4aa7-d510-5966d9865939","executionInfo":{"status":"ok","timestamp":1579353039165,"user_tz":-330,"elapsed":1830,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["num_classes = 2\n","print(np.unique(unseen_l,return_counts=True))\n","unseen_l= np_utils.to_categorical(unseen_l, num_classes)\n","print(unseen_l.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(array([0., 1.], dtype=float32), array([  75, 2763]))\n","(2838, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sy-N7wJBKIA3","colab_type":"code","outputId":"f03bee50-9029-4585-85e8-fc7aae975a55","executionInfo":{"status":"ok","timestamp":1579353043161,"user_tz":-330,"elapsed":2524,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["model.evaluate(unseen_d,unseen_l)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2838/2838 [==============================] - 2s 537us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.5271311750119634, 0.7357293869341823]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"qbNAFob8KLDT","colab_type":"code","outputId":"9fcfd677-b994-4ddf-c129-76a1b3e48d49","executionInfo":{"status":"ok","timestamp":1579353050230,"user_tz":-330,"elapsed":3666,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["import numpy as np\n","from sklearn.metrics import classification_report,confusion_matrix, precision_score\n","import itertools\n","\n","Y_pred = model.predict(unseen_d)\n","y_pred = np.argmax(Y_pred, axis=1)\n","target_names = ['Deffect 0', 'Non deffect 1']\n","print(classification_report(np.argmax(unseen_l,axis=1), y_pred,target_names=target_names))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["               precision    recall  f1-score   support\n","\n","    Deffect 0       0.08      0.80      0.14        75\n","Non deffect 1       0.99      0.73      0.84      2763\n","\n","     accuracy                           0.74      2838\n","    macro avg       0.53      0.77      0.49      2838\n"," weighted avg       0.97      0.74      0.83      2838\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mgGqDb8NKOUO","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    acc=np.trace(cm)/float(np.sum(cm))\n","    miss_class=1-acc\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","    print(acc)\n","    print(miss_class)\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i+0.25 if i==0 else i-0.25, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","        \n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rNTU6eg_KR_l","colab_type":"code","outputId":"448663b2-9753-4c25-bd98-3722aa9b1b70","executionInfo":{"status":"ok","timestamp":1579353052192,"user_tz":-330,"elapsed":1937,"user":{"displayName":"Sai Sree Harsha","photoUrl":"","userId":"07525799085876339757"}},"colab":{"base_uri":"https://localhost:8080/","height":801}},"source":["cnf_matrix = (confusion_matrix(np.argmax(unseen_l,axis=1), y_pred))\n","np.set_printoptions(precision=2)\n","plt.figure(figsize=(10,10))\n","plot_confusion_matrix(cnf_matrix, classes=target_names,\n","                      title='Confusion matrix')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion matrix, without normalization\n","[[  60   15]\n"," [ 735 2028]]\n","0.7357293868921776\n","0.2642706131078224\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAArsAAAK7CAYAAADyY0eCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsP4fSmB7Bk4O5+IAAAAASUVORK5CYII=\n","text/plain":["<Figure size 720x720 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"mOr6RIz2N-oc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}